Model: 'deberta'
Prompt Number: '0'
Number of Examples: '500'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.916
The model's predictions are: [0 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1
 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1
 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1
 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1
 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1
 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1
 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1].
The model's mean prediction is 0.672
CCS accuracy: 0.6799999999999999
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '500'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Loading model
Loading dataloader
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 257.04it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/jigsaw_toxicity_pred/default-data_dir=jigsaw/1.1.0/9cf096ac4341c35839bc8a9f6a19d93e18e5ad3d84cf05f690d2bc6f7384af85/cache-c6571a49730c6301.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors
Generating hidden states
  0%|          | 0/84 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
  1%|          | 1/84 [00:15<21:09, 15.30s/it]  2%|▏         | 2/84 [00:30<20:46, 15.20s/it]  4%|▎         | 3/84 [00:45<20:30, 15.19s/it]  5%|▍         | 4/84 [01:00<20:13, 15.16s/it]  6%|▌         | 5/84 [01:15<19:57, 15.16s/it]  7%|▋         | 6/84 [01:30<19:41, 15.14s/it]  8%|▊         | 7/84 [01:46<19:26, 15.15s/it] 10%|▉         | 8/84 [02:01<19:09, 15.13s/it] 11%|█         | 9/84 [02:16<18:55, 15.13s/it] 12%|█▏        | 10/84 [02:31<18:40, 15.14s/it] 13%|█▎        | 11/84 [02:46<18:24, 15.13s/it] 14%|█▍        | 12/84 [03:01<18:10, 15.14s/it] 15%|█▌        | 13/84 [03:16<17:55, 15.15s/it] 17%|█▋        | 14/84 [03:32<17:40, 15.15s/it] 18%|█▊        | 15/84 [03:47<17:26, 15.16s/it] 19%|█▉        | 16/84 [04:02<17:10, 15.16s/it] 20%|██        | 17/84 [04:17<16:54, 15.14s/it] 21%|██▏       | 18/84 [04:32<16:38, 15.13s/it] 23%|██▎       | 19/84 [04:47<16:25, 15.16s/it] 24%|██▍       | 20/84 [05:03<16:09, 15.15s/it] 25%|██▌       | 21/84 [05:18<15:54, 15.15s/it] 26%|██▌       | 22/84 [05:33<15:38, 15.14s/it] 27%|██▋       | 23/84 [05:48<15:22, 15.13s/it] 29%|██▊       | 24/84 [06:03<15:08, 15.13s/it] 30%|██▉       | 25/84 [06:18<14:53, 15.14s/it] 31%|███       | 26/84 [06:33<14:38, 15.15s/it] 32%|███▏      | 27/84 [06:49<14:23, 15.15s/it] 33%|███▎      | 28/84 [07:04<14:07, 15.14s/it] 35%|███▍      | 29/84 [07:19<13:53, 15.15s/it] 36%|███▌      | 30/84 [07:34<13:38, 15.16s/it] 37%|███▋      | 31/84 [07:49<13:22, 15.15s/it] 38%|███▊      | 32/84 [08:04<13:07, 15.15s/it] 39%|███▉      | 33/84 [08:19<12:52, 15.14s/it] 40%|████      | 34/84 [08:35<12:36, 15.13s/it] 42%|████▏     | 35/84 [08:50<12:21, 15.13s/it] 43%|████▎     | 36/84 [09:05<12:05, 15.12s/it] 44%|████▍     | 37/84 [09:20<11:51, 15.13s/it] 45%|████▌     | 38/84 [09:35<11:36, 15.15s/it] 46%|████▋     | 39/84 [09:50<11:20, 15.13s/it] 48%|████▊     | 40/84 [10:05<11:05, 15.12s/it] 49%|████▉     | 41/84 [10:20<10:50, 15.12s/it] 50%|█████     | 42/84 [10:35<10:35, 15.12s/it] 51%|█████     | 43/84 [10:51<10:19, 15.12s/it] 52%|█████▏    | 44/84 [11:06<10:05, 15.13s/it] 54%|█████▎    | 45/84 [11:21<09:49, 15.12s/it] 55%|█████▍    | 46/84 [11:36<09:35, 15.13s/it] 56%|█████▌    | 47/84 [11:51<09:20, 15.15s/it] 57%|█████▋    | 48/84 [12:06<09:05, 15.17s/it] 58%|█████▊    | 49/84 [12:22<08:50, 15.16s/it] 60%|█████▉    | 50/84 [12:37<08:34, 15.14s/it] 61%|██████    | 51/84 [12:52<08:19, 15.14s/it] 62%|██████▏   | 52/84 [13:07<08:04, 15.14s/it] 63%|██████▎   | 53/84 [13:22<07:49, 15.15s/it] 64%|██████▍   | 54/84 [13:37<07:34, 15.15s/it] 65%|██████▌   | 55/84 [13:52<07:19, 15.14s/it] 67%|██████▋   | 56/84 [14:07<07:03, 15.13s/it] 68%|██████▊   | 57/84 [14:23<06:48, 15.12s/it] 69%|██████▉   | 58/84 [14:38<06:32, 15.11s/it] 70%|███████   | 59/84 [14:53<06:18, 15.14s/it] 71%|███████▏  | 60/84 [15:08<06:03, 15.15s/it] 73%|███████▎  | 61/84 [15:23<05:48, 15.15s/it] 74%|███████▍  | 62/84 [15:38<05:33, 15.14s/it] 75%|███████▌  | 63/84 [15:53<05:17, 15.14s/it] 76%|███████▌  | 64/84 [16:09<05:02, 15.13s/it] 77%|███████▋  | 65/84 [16:24<04:48, 15.17s/it] 79%|███████▊  | 66/84 [16:39<04:32, 15.15s/it] 80%|███████▉  | 67/84 [16:54<04:17, 15.13s/it] 81%|████████  | 68/84 [17:09<04:02, 15.13s/it] 82%|████████▏ | 69/84 [17:24<03:47, 15.13s/it] 83%|████████▎ | 70/84 [17:39<03:32, 15.15s/it] 85%|████████▍ | 71/84 [17:55<03:16, 15.13s/it] 86%|████████▌ | 72/84 [18:10<03:01, 15.12s/it] 87%|████████▋ | 73/84 [18:25<02:46, 15.14s/it] 88%|████████▊ | 74/84 [18:40<02:31, 15.14s/it] 89%|████████▉ | 75/84 [18:55<02:16, 15.14s/it] 90%|█████████ | 76/84 [19:10<02:01, 15.17s/it] 92%|█████████▏| 77/84 [19:26<01:46, 15.17s/it] 93%|█████████▎| 78/84 [19:41<01:30, 15.15s/it] 94%|█████████▍| 79/84 [19:56<01:15, 15.16s/it] 95%|█████████▌| 80/84 [20:11<01:00, 15.16s/it] 96%|█████████▋| 81/84 [20:26<00:45, 15.15s/it] 98%|█████████▊| 82/84 [20:41<00:30, 15.16s/it] 99%|█████████▉| 83/84 [20:56<00:15, 15.17s/it]100%|██████████| 84/84 [21:02<00:00, 12.20s/it]100%|██████████| 84/84 [21:02<00:00, 15.03s/it]
Some weights of the model checkpoint at microsoft/deberta-xxlarge-v2 were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'deberta.embeddings.position_embeddings.weight']
- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xxlarge-v2 and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']
--
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '500'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.908
The model's predictions are: [0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0
 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0
 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1
 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0
 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1].
The model's mean prediction is 0.312
CCS accuracy: 0.636
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '500'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Loading model
Loading dataloader
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 245.25it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/jigsaw_toxicity_pred/default-data_dir=jigsaw/1.1.0/9cf096ac4341c35839bc8a9f6a19d93e18e5ad3d84cf05f690d2bc6f7384af85/cache-c6571a49730c6301.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors
Generating hidden states
  0%|          | 0/84 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
  1%|          | 1/84 [00:15<21:06, 15.26s/it]  2%|▏         | 2/84 [00:30<20:46, 15.20s/it]  4%|▎         | 3/84 [00:45<20:29, 15.17s/it]  5%|▍         | 4/84 [01:00<20:13, 15.17s/it]  6%|▌         | 5/84 [01:15<19:58, 15.17s/it]  7%|▋         | 6/84 [01:31<19:43, 15.17s/it]  8%|▊         | 7/84 [01:46<19:27, 15.16s/it] 10%|▉         | 8/84 [02:01<19:13, 15.17s/it] 11%|█         | 9/84 [02:16<18:56, 15.15s/it] 12%|█▏        | 10/84 [02:31<18:41, 15.16s/it] 13%|█▎        | 11/84 [02:46<18:26, 15.16s/it] 14%|█▍        | 12/84 [03:01<18:10, 15.15s/it] 15%|█▌        | 13/84 [03:17<17:55, 15.14s/it] 17%|█▋        | 14/84 [03:32<17:40, 15.15s/it] 18%|█▊        | 15/84 [03:47<17:26, 15.16s/it] 19%|█▉        | 16/84 [04:02<17:08, 15.13s/it] 20%|██        | 17/84 [04:17<16:53, 15.13s/it] 21%|██▏       | 18/84 [04:32<16:38, 15.12s/it] 23%|██▎       | 19/84 [04:47<16:23, 15.12s/it] 24%|██▍       | 20/84 [05:02<16:07, 15.12s/it] 25%|██▌       | 21/84 [05:18<15:52, 15.11s/it] 26%|██▌       | 22/84 [05:33<15:37, 15.11s/it] 27%|██▋       | 23/84 [05:48<15:22, 15.13s/it] 29%|██▊       | 24/84 [06:03<15:07, 15.13s/it] 30%|██▉       | 25/84 [06:18<14:52, 15.13s/it] 31%|███       | 26/84 [06:33<14:37, 15.12s/it] 32%|███▏      | 27/84 [06:48<14:22, 15.14s/it] 33%|███▎      | 28/84 [07:03<14:07, 15.13s/it] 35%|███▍      | 29/84 [07:19<13:53, 15.15s/it] 36%|███▌      | 30/84 [07:34<13:37, 15.14s/it] 37%|███▋      | 31/84 [07:49<13:22, 15.14s/it] 38%|███▊      | 32/84 [08:04<13:06, 15.13s/it] 39%|███▉      | 33/84 [08:19<12:51, 15.12s/it] 40%|████      | 34/84 [08:34<12:36, 15.13s/it] 42%|████▏     | 35/84 [08:49<12:21, 15.12s/it] 43%|████▎     | 36/84 [09:05<12:06, 15.14s/it] 44%|████▍     | 37/84 [09:20<11:52, 15.15s/it] 45%|████▌     | 38/84 [09:35<11:36, 15.14s/it] 46%|████▋     | 39/84 [09:50<11:21, 15.14s/it] 48%|████▊     | 40/84 [10:05<11:06, 15.15s/it] 49%|████▉     | 41/84 [10:20<10:52, 15.17s/it] 50%|█████     | 42/84 [10:36<10:37, 15.17s/it] 51%|█████     | 43/84 [10:51<10:21, 15.17s/it] 52%|█████▏    | 44/84 [11:06<10:05, 15.15s/it] 54%|█████▎    | 45/84 [11:21<09:50, 15.13s/it] 55%|█████▍    | 46/84 [11:36<09:35, 15.14s/it] 56%|█████▌    | 47/84 [11:51<09:19, 15.13s/it] 57%|█████▋    | 48/84 [12:06<09:05, 15.14s/it] 58%|█████▊    | 49/84 [12:22<08:50, 15.15s/it] 60%|█████▉    | 50/84 [12:37<08:34, 15.14s/it] 61%|██████    | 51/84 [12:52<08:19, 15.14s/it] 62%|██████▏   | 52/84 [13:07<08:04, 15.13s/it] 63%|██████▎   | 53/84 [13:22<07:48, 15.12s/it] 64%|██████▍   | 54/84 [13:37<07:33, 15.12s/it] 65%|██████▌   | 55/84 [13:52<07:18, 15.13s/it] 67%|██████▋   | 56/84 [14:07<07:03, 15.14s/it] 68%|██████▊   | 57/84 [14:23<06:48, 15.13s/it] 69%|██████▉   | 58/84 [14:38<06:33, 15.13s/it] 70%|███████   | 59/84 [14:53<06:18, 15.12s/it] 71%|███████▏  | 60/84 [15:08<06:02, 15.12s/it] 73%|███████▎  | 61/84 [15:23<05:47, 15.13s/it] 74%|███████▍  | 62/84 [15:38<05:33, 15.14s/it] 75%|███████▌  | 63/84 [15:53<05:17, 15.14s/it] 76%|███████▌  | 64/84 [16:08<05:02, 15.14s/it] 77%|███████▋  | 65/84 [16:24<04:47, 15.13s/it] 79%|███████▊  | 66/84 [16:39<04:32, 15.13s/it] 80%|███████▉  | 67/84 [16:54<04:17, 15.15s/it] 81%|████████  | 68/84 [17:09<04:02, 15.14s/it] 82%|████████▏ | 69/84 [17:24<03:47, 15.15s/it] 83%|████████▎ | 70/84 [17:39<03:31, 15.14s/it] 85%|████████▍ | 71/84 [17:54<03:16, 15.14s/it] 86%|████████▌ | 72/84 [18:10<03:01, 15.16s/it] 87%|████████▋ | 73/84 [18:25<02:46, 15.13s/it] 88%|████████▊ | 74/84 [18:40<02:31, 15.13s/it] 89%|████████▉ | 75/84 [18:55<02:16, 15.14s/it] 90%|█████████ | 76/84 [19:10<02:01, 15.13s/it] 92%|█████████▏| 77/84 [19:25<01:45, 15.14s/it] 93%|█████████▎| 78/84 [19:40<01:30, 15.13s/it] 94%|█████████▍| 79/84 [19:56<01:15, 15.15s/it] 95%|█████████▌| 80/84 [20:11<01:00, 15.15s/it] 96%|█████████▋| 81/84 [20:26<00:45, 15.16s/it] 98%|█████████▊| 82/84 [20:41<00:30, 15.16s/it] 99%|█████████▉| 83/84 [20:56<00:15, 15.18s/it]100%|██████████| 84/84 [21:02<00:00, 12.22s/it]100%|██████████| 84/84 [21:02<00:00, 15.03s/it]
Some weights of the model checkpoint at microsoft/deberta-xxlarge-v2 were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'deberta.embeddings.position_embeddings.weight']
- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xxlarge-v2 and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']
--
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '500'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.872
The model's predictions are: [0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1
 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0
 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0
 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1
 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0
 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0].
The model's mean prediction is 0.36
CCS accuracy: 0.66
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '1000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Loading model
Loading dataloader
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 236.91it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/jigsaw_toxicity_pred/default-data_dir=jigsaw/1.1.0/9cf096ac4341c35839bc8a9f6a19d93e18e5ad3d84cf05f690d2bc6f7384af85/cache-c6571a49730c6301.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors
Generating hidden states
  0%|          | 0/167 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
  1%|          | 1/167 [00:15<42:29, 15.36s/it]  1%|          | 2/167 [00:30<41:57, 15.26s/it]  2%|▏         | 3/167 [00:45<41:37, 15.23s/it]  2%|▏         | 4/167 [01:00<41:17, 15.20s/it]  3%|▎         | 5/167 [01:16<40:59, 15.18s/it]  4%|▎         | 6/167 [01:31<40:41, 15.17s/it]  4%|▍         | 7/167 [01:46<40:27, 15.17s/it]  5%|▍         | 8/167 [02:01<40:11, 15.17s/it]  5%|▌         | 9/167 [02:16<39:55, 15.16s/it]  6%|▌         | 10/167 [02:31<39:42, 15.18s/it]  7%|▋         | 11/167 [02:47<39:26, 15.17s/it]  7%|▋         | 12/167 [03:02<39:08, 15.15s/it]  8%|▊         | 13/167 [03:17<38:50, 15.13s/it]  8%|▊         | 14/167 [03:32<38:35, 15.13s/it]  9%|▉         | 15/167 [03:47<38:23, 15.15s/it] 10%|▉         | 16/167 [04:02<38:09, 15.16s/it] 10%|█         | 17/167 [04:17<37:54, 15.17s/it] 11%|█         | 18/167 [04:33<37:40, 15.17s/it] 11%|█▏        | 19/167 [04:48<37:22, 15.15s/it] 12%|█▏        | 20/167 [05:03<37:09, 15.17s/it] 13%|█▎        | 21/167 [05:18<36:52, 15.16s/it] 13%|█▎        | 22/167 [05:33<36:38, 15.16s/it] 14%|█▍        | 23/167 [05:48<36:23, 15.17s/it] 14%|█▍        | 24/167 [06:04<36:07, 15.16s/it] 15%|█▍        | 25/167 [06:19<35:51, 15.15s/it] 16%|█▌        | 26/167 [06:34<35:34, 15.14s/it] 16%|█▌        | 27/167 [06:49<35:21, 15.15s/it] 17%|█▋        | 28/167 [07:04<35:05, 15.15s/it] 17%|█▋        | 29/167 [07:19<34:49, 15.14s/it] 18%|█▊        | 30/167 [07:34<34:33, 15.13s/it] 19%|█▊        | 31/167 [07:49<34:16, 15.12s/it] 19%|█▉        | 32/167 [08:05<34:06, 15.16s/it] 20%|█▉        | 33/167 [08:20<33:51, 15.16s/it] 20%|██        | 34/167 [08:35<33:37, 15.17s/it] 21%|██        | 35/167 [08:50<33:22, 15.17s/it] 22%|██▏       | 36/167 [09:05<33:08, 15.18s/it] 22%|██▏       | 37/167 [09:21<32:52, 15.17s/it] 23%|██▎       | 38/167 [09:36<32:35, 15.16s/it] 23%|██▎       | 39/167 [09:51<32:18, 15.15s/it] 24%|██▍       | 40/167 [10:06<32:03, 15.15s/it] 25%|██▍       | 41/167 [10:21<31:48, 15.14s/it] 25%|██▌       | 42/167 [10:36<31:32, 15.14s/it] 26%|██▌       | 43/167 [10:51<31:20, 15.17s/it] 26%|██▋       | 44/167 [11:07<31:05, 15.16s/it] 27%|██▋       | 45/167 [11:22<30:47, 15.15s/it] 28%|██▊       | 46/167 [11:37<30:33, 15.15s/it] 28%|██▊       | 47/167 [11:52<30:17, 15.15s/it] 29%|██▊       | 48/167 [12:07<30:05, 15.17s/it] 29%|██▉       | 49/167 [12:22<29:49, 15.17s/it] 30%|██▉       | 50/167 [12:38<29:32, 15.15s/it] 31%|███       | 51/167 [12:53<29:16, 15.14s/it] 31%|███       | 52/167 [13:08<29:01, 15.14s/it] 32%|███▏      | 53/167 [13:23<28:46, 15.15s/it] 32%|███▏      | 54/167 [13:38<28:29, 15.13s/it] 33%|███▎      | 55/167 [13:53<28:16, 15.15s/it] 34%|███▎      | 56/167 [14:08<28:00, 15.14s/it] 34%|███▍      | 57/167 [14:24<27:46, 15.15s/it] 35%|███▍      | 58/167 [14:39<27:31, 15.15s/it] 35%|███▌      | 59/167 [14:54<27:15, 15.14s/it] 36%|███▌      | 60/167 [15:09<27:00, 15.14s/it] 37%|███▋      | 61/167 [15:24<26:45, 15.14s/it] 37%|███▋      | 62/167 [15:39<26:30, 15.15s/it] 38%|███▊      | 63/167 [15:54<26:13, 15.13s/it] 38%|███▊      | 64/167 [16:09<25:57, 15.13s/it] 39%|███▉      | 65/167 [16:25<25:44, 15.14s/it] 40%|███▉      | 66/167 [16:40<25:31, 15.16s/it] 40%|████      | 67/167 [16:55<25:18, 15.19s/it] 41%|████      | 68/167 [17:10<25:01, 15.17s/it] 41%|████▏     | 69/167 [17:25<24:45, 15.16s/it] 42%|████▏     | 70/167 [17:40<24:29, 15.15s/it] 43%|████▎     | 71/167 [17:56<24:13, 15.14s/it] 43%|████▎     | 72/167 [18:11<23:57, 15.13s/it] 44%|████▎     | 73/167 [18:26<23:44, 15.15s/it] 44%|████▍     | 74/167 [18:41<23:28, 15.14s/it] 45%|████▍     | 75/167 [18:56<23:12, 15.13s/it] 46%|████▌     | 76/167 [19:11<22:57, 15.14s/it] 46%|████▌     | 77/167 [19:26<22:42, 15.13s/it] 47%|████▋     | 78/167 [19:41<22:26, 15.13s/it] 47%|████▋     | 79/167 [19:57<22:11, 15.13s/it] 48%|████▊     | 80/167 [20:12<21:55, 15.13s/it] 49%|████▊     | 81/167 [20:27<21:39, 15.11s/it] 49%|████▉     | 82/167 [20:42<21:25, 15.12s/it] 50%|████▉     | 83/167 [20:57<21:10, 15.13s/it] 50%|█████     | 84/167 [21:12<20:54, 15.11s/it] 51%|█████     | 85/167 [21:27<20:38, 15.11s/it] 51%|█████▏    | 86/167 [21:42<20:24, 15.12s/it] 52%|█████▏    | 87/167 [21:58<20:11, 15.14s/it] 53%|█████▎    | 88/167 [22:13<19:56, 15.14s/it] 53%|█████▎    | 89/167 [22:28<19:41, 15.14s/it] 54%|█████▍    | 90/167 [22:43<19:26, 15.15s/it] 54%|█████▍    | 91/167 [22:58<19:12, 15.17s/it] 55%|█████▌    | 92/167 [23:13<18:56, 15.16s/it] 56%|█████▌    | 93/167 [23:29<18:41, 15.16s/it] 56%|█████▋    | 94/167 [23:44<18:25, 15.14s/it] 57%|█████▋    | 95/167 [23:59<18:10, 15.15s/it] 57%|█████▋    | 96/167 [24:14<17:55, 15.15s/it] 58%|█████▊    | 97/167 [24:29<17:40, 15.15s/it] 59%|█████▊    | 98/167 [24:44<17:25, 15.15s/it] 59%|█████▉    | 99/167 [24:59<17:09, 15.13s/it] 60%|█████▉    | 100/167 [25:15<16:53, 15.13s/it] 60%|██████    | 101/167 [25:30<16:37, 15.12s/it] 61%|██████    | 102/167 [25:45<16:22, 15.12s/it] 62%|██████▏   | 103/167 [26:00<16:07, 15.12s/it] 62%|██████▏   | 104/167 [26:15<15:53, 15.13s/it] 63%|██████▎   | 105/167 [26:30<15:38, 15.14s/it] 63%|██████▎   | 106/167 [26:45<15:25, 15.17s/it] 64%|██████▍   | 107/167 [27:01<15:09, 15.16s/it] 65%|██████▍   | 108/167 [27:16<14:53, 15.15s/it] 65%|██████▌   | 109/167 [27:31<14:38, 15.14s/it] 66%|██████▌   | 110/167 [27:46<14:24, 15.16s/it] 66%|██████▋   | 111/167 [28:01<14:08, 15.15s/it] 67%|██████▋   | 112/167 [28:16<13:52, 15.13s/it] 68%|██████▊   | 113/167 [28:31<13:37, 15.14s/it] 68%|██████▊   | 114/167 [28:46<13:22, 15.14s/it] 69%|██████▉   | 115/167 [29:02<13:07, 15.15s/it] 69%|██████▉   | 116/167 [29:17<12:52, 15.15s/it] 70%|███████   | 117/167 [29:32<12:37, 15.14s/it] 71%|███████   | 118/167 [29:47<12:22, 15.14s/it] 71%|███████▏  | 119/167 [30:02<12:06, 15.13s/it] 72%|███████▏  | 120/167 [30:17<11:51, 15.13s/it] 72%|███████▏  | 121/167 [30:32<11:36, 15.14s/it] 73%|███████▎  | 122/167 [30:48<11:21, 15.14s/it] 74%|███████▎  | 123/167 [31:03<11:06, 15.14s/it] 74%|███████▍  | 124/167 [31:18<10:50, 15.13s/it] 75%|███████▍  | 125/167 [31:33<10:35, 15.14s/it] 75%|███████▌  | 126/167 [31:48<10:21, 15.16s/it] 76%|███████▌  | 127/167 [32:03<10:05, 15.15s/it] 77%|███████▋  | 128/167 [32:18<09:50, 15.14s/it] 77%|███████▋  | 129/167 [32:34<09:35, 15.14s/it] 78%|███████▊  | 130/167 [32:49<09:20, 15.15s/it] 78%|███████▊  | 131/167 [33:04<09:04, 15.14s/it] 79%|███████▉  | 132/167 [33:19<08:50, 15.15s/it] 80%|███████▉  | 133/167 [33:34<08:34, 15.14s/it] 80%|████████  | 134/167 [33:49<08:20, 15.17s/it] 81%|████████  | 135/167 [34:05<08:05, 15.16s/it] 81%|████████▏ | 136/167 [34:20<07:49, 15.15s/it] 82%|████████▏ | 137/167 [34:35<07:34, 15.16s/it] 83%|████████▎ | 138/167 [34:50<07:19, 15.15s/it] 83%|████████▎ | 139/167 [35:05<07:03, 15.14s/it] 84%|████████▍ | 140/167 [35:20<06:48, 15.13s/it] 84%|████████▍ | 141/167 [35:35<06:33, 15.14s/it] 85%|████████▌ | 142/167 [35:51<06:18, 15.14s/it] 86%|████████▌ | 143/167 [36:06<06:03, 15.15s/it] 86%|████████▌ | 144/167 [36:21<05:48, 15.13s/it] 87%|████████▋ | 145/167 [36:36<05:32, 15.13s/it] 87%|████████▋ | 146/167 [36:51<05:17, 15.13s/it] 88%|████████▊ | 147/167 [37:06<05:02, 15.13s/it] 89%|████████▊ | 148/167 [37:21<04:47, 15.12s/it] 89%|████████▉ | 149/167 [37:36<04:32, 15.14s/it] 90%|████████▉ | 150/167 [37:52<04:17, 15.13s/it] 90%|█████████ | 151/167 [38:07<04:02, 15.13s/it] 91%|█████████ | 152/167 [38:22<03:46, 15.13s/it] 92%|█████████▏| 153/167 [38:37<03:32, 15.16s/it] 92%|█████████▏| 154/167 [38:52<03:16, 15.14s/it] 93%|█████████▎| 155/167 [39:07<03:01, 15.12s/it] 93%|█████████▎| 156/167 [39:22<02:46, 15.13s/it] 94%|█████████▍| 157/167 [39:38<02:31, 15.13s/it] 95%|█████████▍| 158/167 [39:53<02:16, 15.14s/it] 95%|█████████▌| 159/167 [40:08<02:01, 15.14s/it] 96%|█████████▌| 160/167 [40:23<01:46, 15.14s/it] 96%|█████████▋| 161/167 [40:38<01:30, 15.14s/it] 97%|█████████▋| 162/167 [40:53<01:15, 15.13s/it] 98%|█████████▊| 163/167 [41:08<01:00, 15.16s/it] 98%|█████████▊| 164/167 [41:24<00:45, 15.15s/it] 99%|█████████▉| 165/167 [41:39<00:30, 15.16s/it] 99%|█████████▉| 166/167 [41:54<00:15, 15.15s/it]100%|██████████| 167/167 [42:04<00:00, 13.67s/it]100%|██████████| 167/167 [42:04<00:00, 15.12s/it]
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
--
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '1000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.908
The model's predictions are: [0 1 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1
 0 0 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1
 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1
 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0
 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0
 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1
 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0
 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1
 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1
 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0
 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1
 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0
 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1
 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1].
The model's mean prediction is 0.53
CCS accuracy: 0.554
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '1000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Loading model
Loading dataloader
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 242.02it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/jigsaw_toxicity_pred/default-data_dir=jigsaw/1.1.0/9cf096ac4341c35839bc8a9f6a19d93e18e5ad3d84cf05f690d2bc6f7384af85/cache-c6571a49730c6301.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors
--
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '1000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.916
The model's predictions are: [0 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1
 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1
 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1
 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0
 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1
 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0
 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 1
 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0
 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1
 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1
 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1
 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0
 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0
 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0].
The model's mean prediction is 0.462
CCS accuracy: 0.502
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '1000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Loading model
Loading dataloader
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 263.95it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/jigsaw_toxicity_pred/default-data_dir=jigsaw/1.1.0/9cf096ac4341c35839bc8a9f6a19d93e18e5ad3d84cf05f690d2bc6f7384af85/cache-c6571a49730c6301.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors
--
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '1000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.89
The model's predictions are: [1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1
 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1
 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0
 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1
 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1
 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0
 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1
 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1
 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0
 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1
 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1
 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0
 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1
 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1].
The model's mean prediction is 0.738
CCS accuracy: 0.71
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '2000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Loading model
Loading dataloader
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 263.86it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/jigsaw_toxicity_pred/default-data_dir=jigsaw/1.1.0/9cf096ac4341c35839bc8a9f6a19d93e18e5ad3d84cf05f690d2bc6f7384af85/cache-c6571a49730c6301.arrow
Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors
--
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '2000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.9
The model's predictions are: [0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0
 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0
 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0
 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1
 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1
 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0
 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1
 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1
 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1
 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1
 1 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1
 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0
 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0
 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1
 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1
 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1
 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1
 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1
 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1
 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0
 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1
 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1
 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0
 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1
 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1
 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1
 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1
 1].
The model's mean prediction is 0.688
CCS accuracy: 0.7090000000000001
--
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '2000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.919
The model's predictions are: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0].
The model's mean prediction is 0.041
CCS accuracy: 0.878
--
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '2000'
Dataset Name: 'jigsaw_toxicity_pred'
Dataset Directory: 'jigsaw'
No Data Balance: 'True'
Toxicity Threshold: '0'
Logistic regression accuracy: 0.916
The model's predictions are: [0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1
 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0
 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0
 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0
 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0
 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0
 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0
 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1
 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1
 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1
 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1
 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1
 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0
 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0
 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1
 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0
 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1
 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1
 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0
 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1
 1 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1
 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0
 0].
The model's mean prediction is 0.371
CCS accuracy: 0.617
--
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '500'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.9
The model's predictions are: [0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0
 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1
 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0
 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0
 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1
 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0
 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0].
The model's mean prediction is 0.444
CCS accuracy: 0.544
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '500'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Loading model
Loading dataloader
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.56it/s]100%|██████████| 1/1 [00:00<00:00,  8.54it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/csv/jigsaw_unintended_bias-6ea1112a69e329c1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-44bc93a5430ab514.arrow
Generating hidden states
  0%|          | 0/84 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
  1%|          | 1/84 [00:15<21:11, 15.32s/it]  2%|▏         | 2/84 [00:30<20:49, 15.23s/it]  4%|▎         | 3/84 [00:45<20:30, 15.19s/it]  5%|▍         | 4/84 [01:00<20:12, 15.16s/it]  6%|▌         | 5/84 [01:15<19:57, 15.16s/it]  7%|▋         | 6/84 [01:31<19:42, 15.16s/it]  8%|▊         | 7/84 [01:46<19:26, 15.15s/it] 10%|▉         | 8/84 [02:01<19:11, 15.15s/it] 11%|█         | 9/84 [02:16<18:56, 15.16s/it] 12%|█▏        | 10/84 [02:31<18:42, 15.17s/it] 13%|█▎        | 11/84 [02:46<18:27, 15.16s/it] 14%|█▍        | 12/84 [03:02<18:11, 15.17s/it] 15%|█▌        | 13/84 [03:17<17:55, 15.15s/it] 17%|█▋        | 14/84 [03:32<17:40, 15.16s/it] 18%|█▊        | 15/84 [03:47<17:24, 15.14s/it] 19%|█▉        | 16/84 [04:02<17:10, 15.15s/it] 20%|██        | 17/84 [04:17<16:54, 15.14s/it] 21%|██▏       | 18/84 [04:32<16:38, 15.12s/it] 23%|██▎       | 19/84 [04:47<16:23, 15.14s/it] 24%|██▍       | 20/84 [05:03<16:08, 15.14s/it] 25%|██▌       | 21/84 [05:18<15:54, 15.15s/it] 26%|██▌       | 22/84 [05:33<15:38, 15.14s/it] 27%|██▋       | 23/84 [05:48<15:23, 15.13s/it] 29%|██▊       | 24/84 [06:03<15:07, 15.13s/it] 30%|██▉       | 25/84 [06:18<14:53, 15.14s/it] 31%|███       | 26/84 [06:33<14:38, 15.14s/it] 32%|███▏      | 27/84 [06:49<14:23, 15.16s/it] 33%|███▎      | 28/84 [07:04<14:08, 15.16s/it] 35%|███▍      | 29/84 [07:19<13:53, 15.15s/it] 36%|███▌      | 30/84 [07:34<13:37, 15.15s/it] 37%|███▋      | 31/84 [07:49<13:22, 15.15s/it] 38%|███▊      | 32/84 [08:04<13:08, 15.16s/it] 39%|███▉      | 33/84 [08:20<12:52, 15.15s/it] 40%|████      | 34/84 [08:35<12:36, 15.14s/it] 42%|████▏     | 35/84 [08:50<12:22, 15.15s/it] 43%|████▎     | 36/84 [09:05<12:07, 15.15s/it] 44%|████▍     | 37/84 [09:20<11:51, 15.14s/it] 45%|████▌     | 38/84 [09:35<11:36, 15.13s/it] 46%|████▋     | 39/84 [09:50<11:20, 15.12s/it] 48%|████▊     | 40/84 [10:05<11:05, 15.12s/it] 49%|████▉     | 41/84 [10:21<10:50, 15.13s/it] 50%|█████     | 42/84 [10:36<10:35, 15.12s/it] 51%|█████     | 43/84 [10:51<10:19, 15.11s/it] 52%|█████▏    | 44/84 [11:06<10:05, 15.13s/it] 54%|█████▎    | 45/84 [11:21<09:50, 15.14s/it] 55%|█████▍    | 46/84 [11:36<09:35, 15.14s/it] 56%|█████▌    | 47/84 [11:51<09:20, 15.14s/it] 57%|█████▋    | 48/84 [12:06<09:04, 15.13s/it] 58%|█████▊    | 49/84 [12:22<08:49, 15.13s/it] 60%|█████▉    | 50/84 [12:37<08:34, 15.13s/it] 61%|██████    | 51/84 [12:52<08:19, 15.13s/it] 62%|██████▏   | 52/84 [13:07<08:04, 15.14s/it] 63%|██████▎   | 53/84 [13:22<07:49, 15.15s/it] 64%|██████▍   | 54/84 [13:37<07:34, 15.14s/it] 65%|██████▌   | 55/84 [13:52<07:18, 15.13s/it] 67%|██████▋   | 56/84 [14:08<07:03, 15.14s/it] 68%|██████▊   | 57/84 [14:23<06:48, 15.13s/it] 69%|██████▉   | 58/84 [14:38<06:33, 15.14s/it] 70%|███████   | 59/84 [14:53<06:18, 15.14s/it] 71%|███████▏  | 60/84 [15:08<06:03, 15.14s/it] 73%|███████▎  | 61/84 [15:23<05:48, 15.15s/it] 74%|███████▍  | 62/84 [15:38<05:33, 15.14s/it] 75%|███████▌  | 63/84 [15:54<05:17, 15.13s/it] 76%|███████▌  | 64/84 [16:09<05:02, 15.13s/it] 77%|███████▋  | 65/84 [16:24<04:47, 15.13s/it] 79%|███████▊  | 66/84 [16:39<04:32, 15.12s/it] 80%|███████▉  | 67/84 [16:54<04:16, 15.12s/it] 81%|████████  | 68/84 [17:09<04:01, 15.11s/it] 82%|████████▏ | 69/84 [17:24<03:46, 15.13s/it] 83%|████████▎ | 70/84 [17:39<03:31, 15.12s/it] 85%|████████▍ | 71/84 [17:54<03:16, 15.12s/it] 86%|████████▌ | 72/84 [18:10<03:01, 15.13s/it] 87%|████████▋ | 73/84 [18:25<02:46, 15.12s/it] 88%|████████▊ | 74/84 [18:40<02:31, 15.12s/it] 89%|████████▉ | 75/84 [18:55<02:16, 15.14s/it] 90%|█████████ | 76/84 [19:10<02:01, 15.13s/it] 92%|█████████▏| 77/84 [19:25<01:45, 15.12s/it] 93%|█████████▎| 78/84 [19:40<01:30, 15.13s/it] 94%|█████████▍| 79/84 [19:55<01:15, 15.12s/it] 95%|█████████▌| 80/84 [20:11<01:00, 15.12s/it] 96%|█████████▋| 81/84 [20:26<00:45, 15.12s/it] 98%|█████████▊| 82/84 [20:41<00:30, 15.11s/it] 99%|█████████▉| 83/84 [20:56<00:15, 15.12s/it]100%|██████████| 84/84 [21:01<00:00, 12.16s/it]100%|██████████| 84/84 [21:01<00:00, 15.02s/it]
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
--
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '500'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.872
The model's predictions are: [0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0
 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0
 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0
 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1
 0 0 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1
 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1
 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0].
The model's mean prediction is 0.528
CCS accuracy: 0.516
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '500'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Loading model
Loading dataloader
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.39it/s]100%|██████████| 1/1 [00:00<00:00,  8.37it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/csv/jigsaw_unintended_bias-6ea1112a69e329c1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-44bc93a5430ab514.arrow
Generating hidden states
  0%|          | 0/84 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
  1%|          | 1/84 [00:15<21:15, 15.36s/it]  2%|▏         | 2/84 [00:30<20:50, 15.25s/it]  4%|▎         | 3/84 [00:45<20:31, 15.20s/it]  5%|▍         | 4/84 [01:00<20:14, 15.18s/it]  6%|▌         | 5/84 [01:16<19:59, 15.18s/it]  7%|▋         | 6/84 [01:31<19:43, 15.17s/it]  8%|▊         | 7/84 [01:46<19:29, 15.18s/it] 10%|▉         | 8/84 [02:01<19:13, 15.17s/it] 11%|█         | 9/84 [02:16<18:57, 15.17s/it] 12%|█▏        | 10/84 [02:31<18:41, 15.15s/it] 13%|█▎        | 11/84 [02:46<18:25, 15.14s/it] 14%|█▍        | 12/84 [03:01<18:08, 15.12s/it] 15%|█▌        | 13/84 [03:17<17:54, 15.13s/it] 17%|█▋        | 14/84 [03:32<17:39, 15.13s/it] 18%|█▊        | 15/84 [03:47<17:23, 15.12s/it] 19%|█▉        | 16/84 [04:02<17:09, 15.14s/it] 20%|██        | 17/84 [04:17<16:54, 15.15s/it] 21%|██▏       | 18/84 [04:32<16:39, 15.15s/it] 23%|██▎       | 19/84 [04:48<16:24, 15.15s/it] 24%|██▍       | 20/84 [05:03<16:09, 15.14s/it] 25%|██▌       | 21/84 [05:18<15:53, 15.14s/it] 26%|██▌       | 22/84 [05:33<15:38, 15.14s/it] 27%|██▋       | 23/84 [05:48<15:23, 15.14s/it] 29%|██▊       | 24/84 [06:03<15:07, 15.13s/it] 30%|██▉       | 25/84 [06:18<14:52, 15.13s/it] 31%|███       | 26/84 [06:33<14:37, 15.13s/it] 32%|███▏      | 27/84 [06:49<14:23, 15.14s/it] 33%|███▎      | 28/84 [07:04<14:07, 15.14s/it] 35%|███▍      | 29/84 [07:19<13:52, 15.14s/it] 36%|███▌      | 30/84 [07:34<13:37, 15.14s/it] 37%|███▋      | 31/84 [07:49<13:22, 15.14s/it] 38%|███▊      | 32/84 [08:04<13:07, 15.14s/it] 39%|███▉      | 33/84 [08:19<12:51, 15.14s/it] 40%|████      | 34/84 [08:35<12:36, 15.13s/it] 42%|████▏     | 35/84 [08:50<12:21, 15.13s/it] 43%|████▎     | 36/84 [09:05<12:06, 15.14s/it] 44%|████▍     | 37/84 [09:20<11:51, 15.14s/it] 45%|████▌     | 38/84 [09:35<11:37, 15.15s/it] 46%|████▋     | 39/84 [09:50<11:22, 15.16s/it] 48%|████▊     | 40/84 [10:05<11:06, 15.14s/it] 49%|████▉     | 41/84 [10:21<10:51, 15.16s/it] 50%|█████     | 42/84 [10:36<10:36, 15.16s/it] 51%|█████     | 43/84 [10:51<10:21, 15.15s/it] 52%|█████▏    | 44/84 [11:06<10:06, 15.15s/it] 54%|█████▎    | 45/84 [11:21<09:51, 15.16s/it] 55%|█████▍    | 46/84 [11:36<09:35, 15.16s/it] 56%|█████▌    | 47/84 [11:52<09:20, 15.15s/it] 57%|█████▋    | 48/84 [12:07<09:05, 15.15s/it] 58%|█████▊    | 49/84 [12:22<08:50, 15.15s/it] 60%|█████▉    | 50/84 [12:37<08:34, 15.14s/it] 61%|██████    | 51/84 [12:52<08:20, 15.15s/it] 62%|██████▏   | 52/84 [13:07<08:05, 15.16s/it] 63%|██████▎   | 53/84 [13:22<07:49, 15.16s/it] 64%|██████▍   | 54/84 [13:38<07:34, 15.14s/it] 65%|██████▌   | 55/84 [13:53<07:18, 15.13s/it] 67%|██████▋   | 56/84 [14:08<07:03, 15.14s/it] 68%|██████▊   | 57/84 [14:23<06:48, 15.14s/it] 69%|██████▉   | 58/84 [14:38<06:33, 15.13s/it] 70%|███████   | 59/84 [14:53<06:18, 15.13s/it] 71%|███████▏  | 60/84 [15:08<06:03, 15.14s/it] 73%|███████▎  | 61/84 [15:23<05:48, 15.13s/it] 74%|███████▍  | 62/84 [15:39<05:32, 15.12s/it] 75%|███████▌  | 63/84 [15:54<05:17, 15.13s/it] 76%|███████▌  | 64/84 [16:09<05:02, 15.13s/it] 77%|███████▋  | 65/84 [16:24<04:47, 15.12s/it] 79%|███████▊  | 66/84 [16:39<04:32, 15.14s/it] 80%|███████▉  | 67/84 [16:54<04:17, 15.15s/it] 81%|████████  | 68/84 [17:09<04:02, 15.16s/it] 82%|████████▏ | 69/84 [17:25<03:47, 15.14s/it] 83%|████████▎ | 70/84 [17:40<03:32, 15.15s/it] 85%|████████▍ | 71/84 [17:55<03:16, 15.14s/it] 86%|████████▌ | 72/84 [18:10<03:01, 15.15s/it] 87%|████████▋ | 73/84 [18:25<02:46, 15.15s/it] 88%|████████▊ | 74/84 [18:40<02:31, 15.14s/it] 89%|████████▉ | 75/84 [18:55<02:16, 15.14s/it] 90%|█████████ | 76/84 [19:11<02:01, 15.13s/it] 92%|█████████▏| 77/84 [19:26<01:46, 15.14s/it] 93%|█████████▎| 78/84 [19:41<01:30, 15.14s/it] 94%|█████████▍| 79/84 [19:56<01:15, 15.14s/it] 95%|█████████▌| 80/84 [20:11<01:00, 15.15s/it] 96%|█████████▋| 81/84 [20:26<00:45, 15.14s/it] 98%|█████████▊| 82/84 [20:41<00:30, 15.15s/it] 99%|█████████▉| 83/84 [20:57<00:15, 15.15s/it]100%|██████████| 84/84 [21:02<00:00, 12.18s/it]100%|██████████| 84/84 [21:02<00:00, 15.03s/it]
Some weights of the model checkpoint at microsoft/deberta-xxlarge-v2 were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'deberta.embeddings.position_embeddings.weight']
- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-xxlarge-v2 and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
--
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '500'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.888
The model's predictions are: [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0
 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0
 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0
 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0
 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0
 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0
 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 1].
The model's mean prediction is 0.336
CCS accuracy: 0.648
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '1000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Loading model
Loading dataloader
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.47it/s]100%|██████████| 1/1 [00:00<00:00,  8.44it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/csv/jigsaw_unintended_bias-6ea1112a69e329c1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-44bc93a5430ab514.arrow
Generating hidden states
  0%|          | 0/167 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
  1%|          | 1/167 [00:15<42:34, 15.39s/it]  1%|          | 2/167 [00:30<42:00, 15.28s/it]  2%|▏         | 3/167 [00:45<41:37, 15.23s/it]  2%|▏         | 4/167 [01:00<41:17, 15.20s/it]  3%|▎         | 5/167 [01:16<40:59, 15.18s/it]  4%|▎         | 6/167 [01:31<40:42, 15.17s/it]  4%|▍         | 7/167 [01:46<40:26, 15.17s/it]  5%|▍         | 8/167 [02:01<40:11, 15.17s/it]  5%|▌         | 9/167 [02:16<39:57, 15.18s/it]  6%|▌         | 10/167 [02:31<39:41, 15.17s/it]  7%|▋         | 11/167 [02:47<39:24, 15.16s/it]  7%|▋         | 12/167 [03:02<39:08, 15.15s/it]  8%|▊         | 13/167 [03:17<38:52, 15.15s/it]  8%|▊         | 14/167 [03:32<38:38, 15.16s/it]  9%|▉         | 15/167 [03:47<38:24, 15.16s/it] 10%|▉         | 16/167 [04:02<38:08, 15.15s/it] 10%|█         | 17/167 [04:17<37:51, 15.14s/it] 11%|█         | 18/167 [04:33<37:35, 15.14s/it] 11%|█▏        | 19/167 [04:48<37:20, 15.14s/it] 12%|█▏        | 20/167 [05:03<37:06, 15.15s/it] 13%|█▎        | 21/167 [05:18<36:53, 15.16s/it] 13%|█▎        | 22/167 [05:33<36:39, 15.17s/it] 14%|█▍        | 23/167 [05:48<36:22, 15.16s/it] 14%|█▍        | 24/167 [06:03<36:06, 15.15s/it] 15%|█▍        | 25/167 [06:19<35:50, 15.14s/it] 16%|█▌        | 26/167 [06:34<35:35, 15.15s/it] 16%|█▌        | 27/167 [06:49<35:21, 15.16s/it] 17%|█▋        | 28/167 [07:04<35:06, 15.16s/it] 17%|█▋        | 29/167 [07:19<34:50, 15.15s/it] 18%|█▊        | 30/167 [07:34<34:35, 15.15s/it] 19%|█▊        | 31/167 [07:49<34:18, 15.13s/it] 19%|█▉        | 32/167 [08:05<34:01, 15.12s/it] 20%|█▉        | 33/167 [08:20<33:47, 15.13s/it] 20%|██        | 34/167 [08:35<33:33, 15.14s/it] 21%|██        | 35/167 [08:50<33:19, 15.15s/it] 22%|██▏       | 36/167 [09:05<33:02, 15.14s/it] 22%|██▏       | 37/167 [09:20<32:49, 15.15s/it] 23%|██▎       | 38/167 [09:36<32:35, 15.16s/it] 23%|██▎       | 39/167 [09:51<32:19, 15.15s/it] 24%|██▍       | 40/167 [10:06<32:03, 15.15s/it] 25%|██▍       | 41/167 [10:21<31:49, 15.16s/it] 25%|██▌       | 42/167 [10:36<31:34, 15.16s/it] 26%|██▌       | 43/167 [10:51<31:20, 15.16s/it] 26%|██▋       | 44/167 [11:06<31:04, 15.16s/it] 27%|██▋       | 45/167 [11:22<30:48, 15.15s/it] 28%|██▊       | 46/167 [11:37<30:32, 15.15s/it] 28%|██▊       | 47/167 [11:52<30:16, 15.14s/it] 29%|██▊       | 48/167 [12:07<30:02, 15.15s/it] 29%|██▉       | 49/167 [12:22<29:45, 15.13s/it] 30%|██▉       | 50/167 [12:37<29:32, 15.15s/it] 31%|███       | 51/167 [12:52<29:18, 15.16s/it] 31%|███       | 52/167 [13:08<29:03, 15.16s/it] 32%|███▏      | 53/167 [13:23<28:47, 15.15s/it] 32%|███▏      | 54/167 [13:38<28:32, 15.15s/it] 33%|███▎      | 55/167 [13:53<28:17, 15.16s/it] 34%|███▎      | 56/167 [14:08<28:01, 15.15s/it] 34%|███▍      | 57/167 [14:23<27:45, 15.14s/it] 35%|███▍      | 58/167 [14:38<27:29, 15.14s/it] 35%|███▌      | 59/167 [14:54<27:15, 15.14s/it] 36%|███▌      | 60/167 [15:09<27:00, 15.14s/it] 37%|███▋      | 61/167 [15:24<26:44, 15.14s/it] 37%|███▋      | 62/167 [15:39<26:28, 15.13s/it] 38%|███▊      | 63/167 [15:54<26:13, 15.13s/it] 38%|███▊      | 64/167 [16:09<25:58, 15.13s/it] 39%|███▉      | 65/167 [16:24<25:43, 15.13s/it] 40%|███▉      | 66/167 [16:40<25:28, 15.13s/it] 40%|████      | 67/167 [16:55<25:13, 15.13s/it] 41%|████      | 68/167 [17:10<24:58, 15.14s/it] 41%|████▏     | 69/167 [17:25<24:43, 15.14s/it] 42%|████▏     | 70/167 [17:40<24:28, 15.14s/it] 43%|████▎     | 71/167 [17:55<24:14, 15.15s/it] 43%|████▎     | 72/167 [18:10<23:59, 15.15s/it] 44%|████▎     | 73/167 [18:26<23:44, 15.15s/it] 44%|████▍     | 74/167 [18:41<23:28, 15.15s/it] 45%|████▍     | 75/167 [18:56<23:13, 15.14s/it] 46%|████▌     | 76/167 [19:11<22:58, 15.15s/it] 46%|████▌     | 77/167 [19:26<22:44, 15.16s/it] 47%|████▋     | 78/167 [19:41<22:28, 15.15s/it] 47%|████▋     | 79/167 [19:57<22:14, 15.17s/it] 48%|████▊     | 80/167 [20:12<21:59, 15.16s/it] 49%|████▊     | 81/167 [20:27<21:44, 15.17s/it] 49%|████▉     | 82/167 [20:42<21:28, 15.16s/it] 50%|████▉     | 83/167 [20:57<21:12, 15.15s/it] 50%|█████     | 84/167 [21:12<20:57, 15.15s/it] 51%|█████     | 85/167 [21:27<20:43, 15.16s/it] 51%|█████▏    | 86/167 [21:43<20:26, 15.15s/it] 52%|█████▏    | 87/167 [21:58<20:12, 15.15s/it] 53%|█████▎    | 88/167 [22:13<19:57, 15.16s/it] 53%|█████▎    | 89/167 [22:28<19:42, 15.16s/it] 54%|█████▍    | 90/167 [22:43<19:27, 15.16s/it] 54%|█████▍    | 91/167 [22:58<19:11, 15.15s/it] 55%|█████▌    | 92/167 [23:13<18:54, 15.13s/it] 56%|█████▌    | 93/167 [23:29<18:40, 15.14s/it] 56%|█████▋    | 94/167 [23:44<18:24, 15.13s/it] 57%|█████▋    | 95/167 [23:59<18:09, 15.13s/it] 57%|█████▋    | 96/167 [24:14<17:54, 15.14s/it] 58%|█████▊    | 97/167 [24:29<17:39, 15.13s/it] 59%|█████▊    | 98/167 [24:44<17:24, 15.13s/it] 59%|█████▉    | 99/167 [24:59<17:09, 15.13s/it] 60%|█████▉    | 100/167 [25:15<16:54, 15.14s/it] 60%|██████    | 101/167 [25:30<16:39, 15.15s/it] 61%|██████    | 102/167 [25:45<16:24, 15.15s/it] 62%|██████▏   | 103/167 [26:00<16:09, 15.14s/it] 62%|██████▏   | 104/167 [26:15<15:53, 15.13s/it] 63%|██████▎   | 105/167 [26:30<15:38, 15.14s/it] 63%|██████▎   | 106/167 [26:45<15:23, 15.15s/it] 64%|██████▍   | 107/167 [27:01<15:08, 15.14s/it] 65%|██████▍   | 108/167 [27:16<14:54, 15.15s/it] 65%|██████▌   | 109/167 [27:31<14:38, 15.15s/it] 66%|██████▌   | 110/167 [27:46<14:22, 15.14s/it] 66%|██████▋   | 111/167 [28:01<14:07, 15.14s/it] 67%|██████▋   | 112/167 [28:16<13:52, 15.14s/it] 68%|██████▊   | 113/167 [28:31<13:38, 15.15s/it] 68%|██████▊   | 114/167 [28:47<13:23, 15.16s/it] 69%|██████▉   | 115/167 [29:02<13:07, 15.15s/it] 69%|██████▉   | 116/167 [29:17<12:52, 15.15s/it] 70%|███████   | 117/167 [29:32<12:37, 15.15s/it] 71%|███████   | 118/167 [29:47<12:22, 15.15s/it] 71%|███████▏  | 119/167 [30:02<12:07, 15.15s/it] 72%|███████▏  | 120/167 [30:18<11:51, 15.14s/it] 72%|███████▏  | 121/167 [30:33<11:36, 15.14s/it] 73%|███████▎  | 122/167 [30:48<11:20, 15.13s/it] 74%|███████▎  | 123/167 [31:03<11:06, 15.14s/it] 74%|███████▍  | 124/167 [31:18<10:51, 15.15s/it] 75%|███████▍  | 125/167 [31:33<10:35, 15.14s/it] 75%|███████▌  | 126/167 [31:48<10:20, 15.13s/it] 76%|███████▌  | 127/167 [32:03<10:05, 15.14s/it] 77%|███████▋  | 128/167 [32:19<09:50, 15.13s/it] 77%|███████▋  | 129/167 [32:34<09:35, 15.14s/it] 78%|███████▊  | 130/167 [32:49<09:19, 15.13s/it] 78%|███████▊  | 131/167 [33:04<09:05, 15.14s/it] 79%|███████▉  | 132/167 [33:19<08:50, 15.15s/it] 80%|███████▉  | 133/167 [33:34<08:34, 15.14s/it] 80%|████████  | 134/167 [33:49<08:20, 15.15s/it] 81%|████████  | 135/167 [34:05<08:05, 15.16s/it] 81%|████████▏ | 136/167 [34:20<07:49, 15.16s/it] 82%|████████▏ | 137/167 [34:35<07:34, 15.16s/it] 83%|████████▎ | 138/167 [34:50<07:19, 15.16s/it] 83%|████████▎ | 139/167 [35:05<07:04, 15.16s/it] 84%|████████▍ | 140/167 [35:20<06:49, 15.15s/it] 84%|████████▍ | 141/167 [35:36<06:33, 15.14s/it] 85%|████████▌ | 142/167 [35:51<06:18, 15.15s/it] 86%|████████▌ | 143/167 [36:06<06:03, 15.16s/it] 86%|████████▌ | 144/167 [36:21<05:48, 15.16s/it] 87%|████████▋ | 145/167 [36:36<05:33, 15.16s/it] 87%|████████▋ | 146/167 [36:51<05:18, 15.14s/it] 88%|████████▊ | 147/167 [37:06<05:02, 15.13s/it] 89%|████████▊ | 148/167 [37:22<04:47, 15.13s/it] 89%|████████▉ | 149/167 [37:37<04:32, 15.14s/it] 90%|████████▉ | 150/167 [37:52<04:17, 15.13s/it] 90%|█████████ | 151/167 [38:07<04:02, 15.14s/it] 91%|█████████ | 152/167 [38:22<03:46, 15.13s/it] 92%|█████████▏| 153/167 [38:37<03:31, 15.13s/it] 92%|█████████▏| 154/167 [38:52<03:16, 15.13s/it] 93%|█████████▎| 155/167 [39:08<03:01, 15.15s/it] 93%|█████████▎| 156/167 [39:23<02:46, 15.15s/it] 94%|█████████▍| 157/167 [39:38<02:31, 15.14s/it] 95%|█████████▍| 158/167 [39:53<02:16, 15.15s/it] 95%|█████████▌| 159/167 [40:08<02:01, 15.16s/it] 96%|█████████▌| 160/167 [40:23<01:46, 15.16s/it] 96%|█████████▋| 161/167 [40:38<01:30, 15.17s/it] 97%|█████████▋| 162/167 [40:54<01:15, 15.17s/it] 98%|█████████▊| 163/167 [41:09<01:00, 15.17s/it] 98%|█████████▊| 164/167 [41:24<00:45, 15.16s/it] 99%|█████████▉| 165/167 [41:39<00:30, 15.16s/it] 99%|█████████▉| 166/167 [41:54<00:15, 15.15s/it]100%|██████████| 167/167 [42:04<00:00, 13.67s/it]100%|██████████| 167/167 [42:05<00:00, 15.12s/it]
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
--
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '1000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.862
The model's predictions are: [1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0
 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1
 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1
 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1
 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1
 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0
 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1
 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1
 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0
 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1
 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0
 0 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1
 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1].
The model's mean prediction is 0.466
CCS accuracy: 0.552
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '1000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Loading model
Loading dataloader
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.71it/s]100%|██████████| 1/1 [00:00<00:00,  8.69it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/csv/jigsaw_unintended_bias-6ea1112a69e329c1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-44bc93a5430ab514.arrow
Generating hidden states
--
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '1000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.904
The model's predictions are: [1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1
 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0
 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0
 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1
 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 1 0
 1 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 1 1 0
 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0
 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0
 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0
 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 0
 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1
 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0
 1 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0
 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0].
The model's mean prediction is 0.534
CCS accuracy: 0.532
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '1000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Loading model
Loading dataloader
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.67it/s]100%|██████████| 1/1 [00:00<00:00,  6.65it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/csv/jigsaw_unintended_bias-6ea1112a69e329c1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-44bc93a5430ab514.arrow
Generating hidden states
--
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '1000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.846
The model's predictions are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0].
The model's mean prediction is 0.03
CCS accuracy: 0.942
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Running generate with the following arguments:
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '2000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Loading model
Loading dataloader
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.65it/s]100%|██████████| 1/1 [00:00<00:00,  8.62it/s]
Loading cached processed dataset at /home/danielezer/.cache/huggingface/datasets/csv/jigsaw_unintended_bias-6ea1112a69e329c1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-44bc93a5430ab514.arrow
Generating hidden states
--
Model: 'deberta'
Prompt Number: '0'
Number of Examples: '2000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.865
The model's predictions are: [1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0
 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0
 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1
 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1
 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0
 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0
 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1
 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1
 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1
 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1
 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1
 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0
 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0
 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1
 1 0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1
 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1
 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0
 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 1 1
 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0
 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1
 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1
 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1
 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1
 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0
 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1
 0].
The model's mean prediction is 0.435
CCS accuracy: 0.564
--
Model: 'deberta'
Prompt Number: '1'
Number of Examples: '2000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.888
The model's predictions are: [0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0
 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1
 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1
 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0
 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 0
 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1
 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0
 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1
 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0
 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0
 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1
 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0
 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1
 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0
 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0
 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0
 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0
 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1
 1 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1
 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0
 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1
 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1
 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0
 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0
 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0
 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0
 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1
 1].
The model's mean prediction is 0.542
CCS accuracy: 0.544
--
Model: 'deberta'
Prompt Number: '2'
Number of Examples: '2000'
Dataset Name: 'jigsaw_unintended_bias'
Dataset Directory: 'jigsaw_unintended_bias'
No Data Balance: 'True'
Toxicity Threshold: '0.6'
Logistic regression accuracy: 0.872
The model's predictions are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0].
The model's mean prediction is 0.006
CCS accuracy: 0.951
